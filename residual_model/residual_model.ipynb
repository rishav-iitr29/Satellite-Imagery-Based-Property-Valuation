{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14338310,"sourceType":"datasetVersion","datasetId":9154501},{"sourceId":14344330,"sourceType":"datasetVersion","datasetId":9158965}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I trained all the models on Kaggle and hence the file paths are according to them. If running locally, replace them with the commented one beside them (they are fixed in beginning of the code only).<br> Also change for the test dataset accordingly","metadata":{}},{"cell_type":"code","source":"# Importing all the required libraries\nimport os\nimport numpy as np\nfrom scipy.sparse import issparse\nfrom PIL import Image\nimport tqdm\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, r2_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T21:56:48.431057Z","iopub.execute_input":"2026-01-04T21:56:48.431384Z","iopub.status.idle":"2026-01-04T21:56:53.655443Z","shell.execute_reply.started":"2026-01-04T21:56:48.431356Z","shell.execute_reply":"2026-01-04T21:56:53.654890Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data_path = '/kaggle/input/tabular-data/' # '../data/processed/'\nimage_dir = '/kaggle/input/imagery-train/' # '../data/images/train/images/'\nsave_model_dir = '/kaggle/working/' # '/model_output/'\n\n# LOADING DATA\n\nprint(\"Loading data...\")\n\nif os.path.exists(f'{data_path}X_train.npy'):\n    X_train = np.load(f'{data_path}X_train.npy', allow_pickle=True)\n    y_train = np.load(f'{data_path}y_train.npy', allow_pickle=True)\n    train_ids = np.load(f'{data_path}train_ids.npy', allow_pickle=True)\n    X_val = np.load(f'{data_path}X_val.npy', allow_pickle=True)\n    y_val = np.load(f'{data_path}y_val.npy', allow_pickle=True)\n    val_ids = np.load(f'{data_path}val_ids.npy', allow_pickle=True)\n\n    # Handle Sparse/Wrapped Inputs\n    if X_train.shape == (): X_train = X_train.item()\n    if X_val.shape == (): X_val = X_val.item()\n    if issparse(X_train): X_train = X_train.toarray().astype(np.float32)\n    else: X_train = np.array(X_train, dtype=np.float32)\n    if issparse(X_val): X_val = X_val.toarray().astype(np.float32)\n    else: X_val = np.array(X_val, dtype=np.float32)\n\n    y_train = y_train.astype(np.float32)\n    y_val = y_val.astype(np.float32)\n    print(f\"Data Loaded. Train: {X_train.shape}, Val: {X_val.shape}\")\nelse:\n    raise FileNotFoundError(\"Please run the preprocessing script to generate .npy files first.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T21:57:04.346472Z","iopub.execute_input":"2026-01-04T21:57:04.347201Z","iopub.status.idle":"2026-01-04T21:57:04.458590Z","shell.execute_reply.started":"2026-01-04T21:57:04.347171Z","shell.execute_reply":"2026-01-04T21:57:04.458042Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nData Loaded. Train: (12888, 64), Val: (3222, 64)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1. Train XGBoost (The \"Base\" Model)\nprint(\"Training XGBoost Baseline...\")\n\n\nxgb_reg = xgb.XGBRegressor(\n    n_estimators=1000,\n    learning_rate=0.05,\n    max_depth=6,\n    early_stopping_rounds=50,\n    random_state=42,\n    n_jobs=-1\n)\n\nxgb_reg.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    verbose=False\n)\n\nxgb_train_preds = xgb_reg.predict(X_train)\nxgb_val_preds = xgb_reg.predict(X_val)\n\n\ntrain_residuals = y_train - xgb_train_preds\nval_residuals = y_val - xgb_val_preds\n\n\nbaseline_rmse = np.sqrt(mean_squared_error(y_val, xgb_val_preds))\nbaseline_r2 = r2_score(y_val, xgb_val_preds)\nprint(f\"XGBoost Baseline RMSE: {baseline_rmse:.4f}\")\nprint(f\"XGBoost Baseline R2: {baseline_r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T21:57:11.143036Z","iopub.execute_input":"2026-01-04T21:57:11.143331Z","iopub.status.idle":"2026-01-04T21:57:13.332892Z","shell.execute_reply.started":"2026-01-04T21:57:11.143304Z","shell.execute_reply":"2026-01-04T21:57:13.332073Z"}},"outputs":[{"name":"stdout","text":"Training XGBoost Baseline...\nXGBoost Baseline RMSE: 0.1847\nXGBoost Baseline R2: 0.8743\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nclass MultimodalDataset(Dataset):\n    def __init__(self, X_tabular, y_labels, property_ids, image_dir, transform=None):\n        self.X_tabular = torch.FloatTensor(X_tabular)\n        self.y_labels = torch.FloatTensor(y_labels)\n        self.property_ids = property_ids\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.property_ids)\n\n    def __getitem__(self, idx):\n        tabular_features = self.X_tabular[idx]\n        label = self.y_labels[idx]\n\n        property_id = self.property_ids[idx]\n        image_path = os.path.join(self.image_dir, f\"{property_id}.png\")\n\n        try:\n            image = Image.open(image_path).convert('RGB')\n        except:\n            image = Image.new('RGB', (224, 224), color='black') # Fallback\n\n        if self.transform:\n            image = self.transform(image)\n\n        return {\n            'image': image,\n            'tabular': tabular_features,\n            'label': label,\n            'id': property_id\n        }\n\nclass ResidualMultimodalModel(nn.Module):\n    \"\"\"\n    Residual Multimodal Model:\n    price = base_tabular_prediction + image_residual(tabular, image)\n    \"\"\"\n\n    def __init__(self, tabular_dim):\n        super().__init__()\n\n        # Vision Backbone (Frozen)\n        self.backbone = models.resnet50(\n            weights=models.ResNet50_Weights.DEFAULT\n        )\n        img_dim = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n\n        # Freeze ENTIRE CNN\n        for p in self.backbone.parameters():\n            p.requires_grad = False\n\n        # Tabular Projection (Small)\n        self.tabular_proj = nn.Sequential(\n            nn.Linear(tabular_dim, 64),\n            nn.ReLU()\n        )\n\n        # Residual Head (HEAVILY REGULARIZED)\n        self.residual_head = nn.Sequential(\n            nn.Linear(img_dim + 64, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, 1)\n        )\n\n    def forward(self, image, tabular):\n        with torch.no_grad():\n            img_feats = self.backbone(image)  # frozen\n\n        tab_feats = self.tabular_proj(tabular)\n\n        x = torch.cat([img_feats, tab_feats], dim=1)\n        residual = self.residual_head(x)\n\n        return residual.squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T21:57:23.986012Z","iopub.execute_input":"2026-01-04T21:57:23.986607Z","iopub.status.idle":"2026-01-04T21:57:38.524214Z","shell.execute_reply.started":"2026-01-04T21:57:23.986577Z","shell.execute_reply":"2026-01-04T21:57:38.523513Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Standard Transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset_res = MultimodalDataset(X_train, train_residuals, train_ids, image_dir, transform)\nval_dataset_res = MultimodalDataset(X_val, val_residuals, val_ids, image_dir, transform)\n\ntrain_loader_res = DataLoader(train_dataset_res, batch_size=32, shuffle=True, num_workers=2)\nval_loader_res = DataLoader(val_dataset_res, batch_size=32, shuffle=False, num_workers=2)\n\n\n# Training setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ResidualMultimodalModel(tabular_dim=X_train.shape[1]).to(device)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=1e-4,\n    weight_decay=1e-2\n)\n\n# Training Loop\nepochs = 15\nbest_rmse = float(\"inf\")\n\nfor epoch in range(epochs):\n    model.train()\n    train_loss = 0.0\n\n    for batch in tqdm.tqdm(train_loader_res, desc=f\"Epoch {epoch+1}\", leave=False):\n        images = batch['image'].to(device)\n        tabular = batch['tabular'].to(device)\n        targets = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        preds = model(images, tabular)\n        loss = criterion(preds, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # VALIDATION\n    model.eval()\n    cnn_residual_preds = []\n\n    with torch.no_grad():\n        for batch in val_loader_res:\n            images = batch['image'].to(device)\n            tabular = batch['tabular'].to(device)\n            preds = model(images, tabular)\n            cnn_residual_preds.extend(preds.cpu().numpy())\n\n    cnn_residual_preds = np.array(cnn_residual_preds)\n\n    # COMBINE WITH TABULAR BASE\n    alpha = 0.5\n    final_preds = xgb_val_preds + alpha * cnn_residual_preds\n\n    rmse = np.sqrt(mean_squared_error(y_val, final_preds))\n    r2   = r2_score(y_val, final_preds)\n\n    print(\n        f\"Epoch {epoch+1} | \"\n        f\"Train Residual Loss: {train_loss/len(train_loader_res):.6f} | \"\n        f\"Combined RMSE: {rmse:.4f} | \"\n        f\"R²: {r2:.4f}\"\n    )\n\n    if rmse < best_rmse:\n        best_rmse = rmse\n        torch.save(model.state_dict(), f\"{save_model_dir}best_residual_multimodal.pth\")\n        print(f\"  Saved new best model (RMSE: {best_rmse:.4f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T21:58:04.454519Z","iopub.execute_input":"2026-01-04T21:58:04.454908Z","iopub.status.idle":"2026-01-04T22:17:55.303279Z","shell.execute_reply.started":"2026-01-04T21:58:04.454880Z","shell.execute_reply":"2026-01-04T22:17:55.302255Z"}},"outputs":[{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Residual Loss: 0.015399 | Combined RMSE: 0.1842 | R²: 0.8750\n  Saved new best model (RMSE: 0.1842)\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Residual Loss: 0.014765 | Combined RMSE: 0.1838 | R²: 0.8754\n  Saved new best model (RMSE: 0.1838)\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Residual Loss: 0.014570 | Combined RMSE: 0.1837 | R²: 0.8756\n  Saved new best model (RMSE: 0.1837)\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Residual Loss: 0.014299 | Combined RMSE: 0.1837 | R²: 0.8756\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Residual Loss: 0.014167 | Combined RMSE: 0.1834 | R²: 0.8760\n  Saved new best model (RMSE: 0.1834)\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Residual Loss: 0.013771 | Combined RMSE: 0.1834 | R²: 0.8760\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Residual Loss: 0.013530 | Combined RMSE: 0.1836 | R²: 0.8758\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Residual Loss: 0.013047 | Combined RMSE: 0.1830 | R²: 0.8766\n  Saved new best model (RMSE: 0.1830)\n","output_type":"stream"},{"name":"stderr","text":"                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Residual Loss: 0.012594 | Combined RMSE: 0.1827 | R²: 0.8770\n  Saved new best model (RMSE: 0.1827)\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Residual Loss: 0.012296 | Combined RMSE: 0.1835 | R²: 0.8759\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | Train Residual Loss: 0.011847 | Combined RMSE: 0.1830 | R²: 0.8765\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | Train Residual Loss: 0.011390 | Combined RMSE: 0.1827 | R²: 0.8769\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | Train Residual Loss: 0.011168 | Combined RMSE: 0.1825 | R²: 0.8772\n  Saved new best model (RMSE: 0.1825)\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | Train Residual Loss: 0.010631 | Combined RMSE: 0.1823 | R²: 0.8775\n  Saved new best model (RMSE: 0.1823)\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | Train Residual Loss: 0.010401 | Combined RMSE: 0.1830 | R²: 0.8765\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Apparantely, I could not figure out the visualising part for this model and hence only training part is there","metadata":{}}]}